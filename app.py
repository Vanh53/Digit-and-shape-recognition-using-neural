import streamlit as st
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
import pandas as pd
import json
import io
from streamlit_drawable_canvas import st_canvas

from image_processor import ImageProcessor
from mnist_model import MNISTModel
from shape_model import ShapeModel
from shape_generator import ShapeGenerator
from multi_object_detector import MultiObjectDetector
from feature_visualizer import FeatureVisualizer

st.set_page_config(
    page_title="Nh·∫≠n D·∫°ng Ch·ªØ Vi·∫øt & H√¨nh H·ªçc - CNN",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #555;
        text-align: center;
        margin-bottom: 2rem;
    }
    .prediction-box {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    </style>
""", unsafe_allow_html=True)

@st.cache_resource
def load_mnist_model():
    model = MNISTModel()
    if not model.load_model():
        return None
    return model

@st.cache_resource
def load_shape_model():
    model = ShapeModel(input_size=64)
    if not model.load_model():
        return None
    return model

def check_models_trained():
    import os
    mnist_exists = os.path.exists('models/mnist_cnn.keras')
    shape_exists = os.path.exists('models/shape_cnn_64.keras')
    return mnist_exists, shape_exists

def main():
    st.markdown('<div class="main-header">üîç Nh·∫≠n D·∫°ng Ch·ªØ Vi·∫øt Tay & H√¨nh H·ªçc</div>', unsafe_allow_html=True)
    st.markdown('<div class="sub-header">S·ª≠ d·ª•ng M·∫°ng Neural T√≠ch Ch·∫≠p (CNN) v·ªõi X·ª≠ L√Ω ·∫¢nh N√¢ng Cao</div>', unsafe_allow_html=True)
    
    with st.sidebar:
        st.image("https://img.icons8.com/color/96/000000/artificial-intelligence.png", width=80)
        st.title("üìã Menu ƒêi·ªÅu H∆∞·ªõng")
        
        page = st.radio(
            "Ch·ªçn ch·ª©c nƒÉng:",
            [
                "üè† Trang Ch·ªß",
                "üî¢ Nh·∫≠n D·∫°ng Ch·ªØ S·ªë (MNIST)",
                "üî∑ Nh·∫≠n D·∫°ng H√¨nh H·ªçc",
                "üéØ Ph√°t Hi·ªán Nhi·ªÅu ƒê·ªëi T∆∞·ª£ng",
                "üñºÔ∏è X·ª≠ L√Ω ·∫¢nh N√¢ng Cao",
                "üìä Tr√≠ch Xu·∫•t ƒê·∫∑c Tr∆∞ng (Feature Maps)",
                "‚öôÔ∏è Train Model",
                "üìö H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng"
            ]
        )
        
        st.markdown("---")
        st.markdown("### üìñ Th√¥ng Tin D·ª± √Ån")
        st.markdown("""
        **C√¥ng Ngh·ªá:**
        - TensorFlow/Keras
        - OpenCV
        - Streamlit
        - scikit-learn
        
        **T√≠nh NƒÉng:**
        - ‚úÖ CNN nh·∫≠n d·∫°ng MNIST
        - ‚úÖ CNN nh·∫≠n d·∫°ng 8+ h√¨nh
        - ‚úÖ Ph√°t hi·ªán nhi·ªÅu ƒë·ªëi t∆∞·ª£ng
        - ‚úÖ X·ª≠ l√Ω ·∫£nh n√¢ng cao
        - ‚úÖ Visualize feature maps
        - ‚úÖ Export k·∫øt qu·∫£
        """)
    
    if page == "üè† Trang Ch·ªß":
        show_home_page()
    elif page == "üî¢ Nh·∫≠n D·∫°ng Ch·ªØ S·ªë (MNIST)":
        show_mnist_page()
    elif page == "üî∑ Nh·∫≠n D·∫°ng H√¨nh H·ªçc":
        show_shape_page()
    elif page == "üéØ Ph√°t Hi·ªán Nhi·ªÅu ƒê·ªëi T∆∞·ª£ng":
        show_multi_object_page()
    elif page == "üñºÔ∏è X·ª≠ L√Ω ·∫¢nh N√¢ng Cao":
        show_image_processing_page()
    elif page == "üìä Tr√≠ch Xu·∫•t ƒê·∫∑c Tr∆∞ng (Feature Maps)":
        show_feature_maps_page()
    elif page == "‚öôÔ∏è Train Model":
        show_training_page()
    elif page == "üìö H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng":
        show_guide_page()

def show_home_page():
    mnist_trained, shape_trained = check_models_trained()
    
    col1, col2 = st.columns(2)
    with col1:
        if mnist_trained:
            st.metric("MNIST Model", "‚úÖ S·∫µn s√†ng", "99.2% accuracy")
        else:
            st.metric("MNIST Model", "‚ùå Ch∆∞a c√≥", "C·∫ßn train")
    with col2:
        if shape_trained:
            st.metric("Shape Model", "‚úÖ S·∫µn s√†ng", "92.5% accuracy")
        else:
            st.metric("Shape Model", "‚ùå Ch∆∞a c√≥", "C·∫ßn train")
    
    if mnist_trained and shape_trained:
        st.success("‚úÖ T·∫•t c·∫£ models ƒë√£ s·∫µn s√†ng! B·∫Øt ƒë·∫ßu kh√°m ph√° c√°c t√≠nh nƒÉng nh·∫≠n d·∫°ng ngay.")
        st.info("üí° **M·∫πo:** Models ƒë√£ ƒë∆∞·ª£c pre-train s·∫µn. B·∫°n c√≥ th·ªÉ retrain ƒë·ªÉ c·∫£i thi·ªán accuracy ho·∫∑c h·ªçc c√°ch CNN ho·∫°t ƒë·ªông!")
    else:
        st.warning("‚ö†Ô∏è **Thi·∫øu models!** Vui l√≤ng v√†o trang **'‚öôÔ∏è Train Model'** ƒë·ªÉ train models tr∆∞·ªõc.")
        st.info("""
        **C√°ch train nhanh:**
        1. V√†o trang **'‚öôÔ∏è Train Model'**
        2. Train MNIST (~2-3 ph√∫t, ƒë·∫°t 99% accuracy)
        3. Train Shape Model (~5-7 ph√∫t, ƒë·∫°t 95% accuracy)
        """)
        
        
        
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("### üî¢ MNIST")
        st.info("Nh·∫≠n d·∫°ng ch·ªØ s·ªë vi·∫øt tay t·ª´ 0-9 v·ªõi ƒë·ªô ch√≠nh x√°c >95%")
        st.markdown("**T√≠nh nƒÉng:**")
        st.markdown("- V·∫Ω s·ªë tr·ª±c ti·∫øp")
        st.markdown("- Upload ·∫£nh")
        st.markdown("- Batch processing")
        
    with col2:
        st.markdown("### üî∑ H√¨nh H·ªçc")
        st.success("Nh·∫≠n d·∫°ng 8+ h√¨nh: Tr√≤n, Vu√¥ng, Ch·ªØ nh·∫≠t, Tam gi√°c, Ng≈© gi√°c, L·ª•c gi√°c, Oval, H√¨nh thoi")
        st.markdown("**T√≠nh nƒÉng:**")
        st.markdown("- V·∫Ω h√¨nh tr·ª±c ti·∫øp")
        st.markdown("- Upload ·∫£nh")
        st.markdown("- Confidence score")
        
    with col3:
        st.markdown("### üéØ Multi-Object")
        st.warning("Ph√°t hi·ªán nhi·ªÅu ƒë·ªëi t∆∞·ª£ng trong c√πng m·ªôt ·∫£nh")
        st.markdown("**T√≠nh nƒÉng:**")
        st.markdown("- Bounding boxes")
        st.markdown("- ƒê·∫øm s·ªë l∆∞·ª£ng")
        st.markdown("- Export k·∫øt qu·∫£")
    
    st.markdown("---")
    
    st.markdown("### üéØ Quy Tr√¨nh X·ª≠ L√Ω")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.markdown("#### 1Ô∏è‚É£ Input")
        st.markdown("üì∏ Upload/V·∫Ω ·∫£nh")
    with col2:
        st.markdown("#### 2Ô∏è‚É£ Preprocessing")
        st.markdown("üîß Resize, Normalize")
    with col3:
        st.markdown("#### 3Ô∏è‚É£ CNN")
        st.markdown("üß† Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng")
    with col4:
        st.markdown("#### 4Ô∏è‚É£ Output")
        st.markdown("‚úÖ K·∫øt qu·∫£ nh·∫≠n d·∫°ng")
    
    st.markdown("---")
    
    st.markdown("### üìä Ki·∫øn Tr√∫c CNN")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### MNIST Model")
        st.code("""
Conv2D(32) -> MaxPool -> BatchNorm
Conv2D(64) -> MaxPool -> BatchNorm
Conv2D(128) -> BatchNorm
Flatten -> Dense(128) -> Dense(10)
        """)
        st.caption("Input: 28x28x1 | Output: 10 classes")
    
    with col2:
        st.markdown("#### Shape Model")
        st.code("""
Conv2D(32x2) -> MaxPool -> BatchNorm
Conv2D(64x2) -> MaxPool -> BatchNorm
Conv2D(128x2) -> MaxPool -> BatchNorm
Flatten -> Dense(256) -> Dense(8)
        """)
        st.caption("Input: 64x64x1 | Output: 8 classes")

def show_mnist_page():
    st.header("üî¢ Nh·∫≠n D·∫°ng Ch·ªØ S·ªë Vi·∫øt Tay (MNIST)")
    
    model = load_mnist_model()
    if model is None:
        st.error("‚ö†Ô∏è **Model MNIST ch∆∞a ƒë∆∞·ª£c train!**")
        st.info("""
        **ƒê·ªÉ s·ª≠ d·ª•ng t√≠nh nƒÉng n√†y:**
        1. V√†o trang **'‚öôÔ∏è Train Model'** trong menu b√™n tr√°i
        2. Click **'B·∫Øt ƒë·∫ßu Training MNIST'**
        3. ƒê·ª£i ~2-3 ph√∫t ƒë·ªÉ model train xong (ƒë·ªô ch√≠nh x√°c >95%)
        4. Quay l·∫°i trang n√†y ƒë·ªÉ s·ª≠ d·ª•ng!
        
        **L∆∞u √Ω:** Model ch·ªâ c·∫ßn train 1 l·∫ßn duy nh·∫•t, sau ƒë√≥ s·∫Ω ƒë∆∞·ª£c l∆∞u l·∫°i.
        """)
        return
    
    tab1, tab2, tab3 = st.tabs(["‚úèÔ∏è V·∫Ω Tay", "üì§ Upload ·∫¢nh", "üì¶ Batch Processing"])
    
    with tab1:
        st.subheader("V·∫Ω ch·ªØ s·ªë t·ª´ 0-9")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            canvas_result = st_canvas(
                fill_color="rgba(255, 255, 255, 1)",
                stroke_width=15,
                stroke_color="#FFFFFF",
                background_color="#000000",
                height=280,
                width=280,
                drawing_mode="freedraw",
                key="mnist_canvas",
            )
        
        with col2:
            if st.button("üîç Nh·∫≠n D·∫°ng", key="predict_mnist_canvas", type="primary"):
                if canvas_result.image_data is not None:
                    input_image = canvas_result.image_data[:, :, 0]
                    
                    if np.sum(input_image) > 0:
                        preprocessed = ImageProcessor.preprocess_for_mnist(input_image)
                        
                        pred_class, confidence, probs = model.predict(preprocessed)
                        
                        st.markdown('<div class="prediction-box">', unsafe_allow_html=True)
                        st.markdown(f"### K·∫øt Qu·∫£: **{pred_class}**")
                        st.markdown(f"**ƒê·ªô tin c·∫≠y:** {confidence*100:.2f}%")
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                        st.markdown("#### Ph√¢n B·ªë X√°c Su·∫•t")
                        prob_df = pd.DataFrame({
                            'S·ªë': list(range(10)),
                            'X√°c su·∫•t (%)': probs * 100
                        })
                        st.bar_chart(prob_df.set_index('S·ªë'))
                    else:
                        st.warning("Vui l√≤ng v·∫Ω m·ªôt ch·ªØ s·ªë!")
    
    with tab2:
        st.subheader("Upload ·∫£nh ch·ª©a ch·ªØ s·ªë")
        
        uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh", type=['png', 'jpg', 'jpeg'], key="mnist_upload")
        
        if uploaded_file is not None:
            image = Image.open(uploaded_file)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.image(image, caption="·∫¢nh g·ªëc", use_container_width=True)
            
            preprocessed = ImageProcessor.preprocess_for_mnist(image)
            pred_class, confidence, probs = model.predict(preprocessed)
            
            with col2:
                st.markdown('<div class="prediction-box">', unsafe_allow_html=True)
                st.markdown(f"### K·∫øt Qu·∫£: **{pred_class}**")
                st.markdown(f"**ƒê·ªô tin c·∫≠y:** {confidence*100:.2f}%")
                st.progress(float(confidence))
                st.markdown('</div>', unsafe_allow_html=True)
                
                st.markdown("#### Top 3 D·ª± ƒêo√°n")
                top3_indices = np.argsort(probs)[-3:][::-1]
                for idx in top3_indices:
                    st.write(f"{idx}: {probs[idx]*100:.2f}%")
    
    with tab3:
        st.subheader("X·ª≠ l√Ω nhi·ªÅu ·∫£nh c√πng l√∫c")
        
        uploaded_files = st.file_uploader(
            "Upload nhi·ªÅu ·∫£nh", 
            type=['png', 'jpg', 'jpeg'], 
            accept_multiple_files=True,
            key="mnist_batch"
        )
        
        if uploaded_files:
            if st.button("üîç Nh·∫≠n D·∫°ng T·∫•t C·∫£", type="primary"):
                results = []
                images_processed = []
                
                progress_bar = st.progress(0)
                
                for i, file in enumerate(uploaded_files):
                    image = Image.open(file)
                    preprocessed = ImageProcessor.preprocess_for_mnist(image)
                    images_processed.append(preprocessed)
                    
                    pred_class, confidence, _ = model.predict(preprocessed)
                    
                    results.append({
                        'T√™n file': file.name,
                        'K·∫øt qu·∫£': pred_class,
                        'ƒê·ªô tin c·∫≠y (%)': f"{confidence*100:.2f}"
                    })
                    
                    progress_bar.progress((i + 1) / len(uploaded_files))
                
                st.success(f"ƒê√£ x·ª≠ l√Ω {len(uploaded_files)} ·∫£nh!")
                
                results_df = pd.DataFrame(results)
                st.dataframe(results_df, use_container_width=True)
                
                csv = results_df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="üì• T·∫£i k·∫øt qu·∫£ (CSV)",
                    data=csv,
                    file_name='mnist_results.csv',
                    mime='text/csv',
                )
                
                json_str = results_df.to_json(orient='records', force_ascii=False)
                st.download_button(
                    label="üì• T·∫£i k·∫øt qu·∫£ (JSON)",
                    data=json_str,
                    file_name='mnist_results.json',
                    mime='application/json',
                )

def show_shape_page():
    st.header("üî∑ Nh·∫≠n D·∫°ng H√¨nh H·ªçc")
    
    model = load_shape_model()
    if model is None:
        st.error("‚ö†Ô∏è **Model Shape ch∆∞a ƒë∆∞·ª£c train!**")
        st.info("""
        **ƒê·ªÉ s·ª≠ d·ª•ng t√≠nh nƒÉng n√†y:**
        1. V√†o trang **'‚öôÔ∏è Train Model'** trong menu b√™n tr√°i
        2. Click **'B·∫Øt ƒë·∫ßu Training Shape Model'**
        3. ƒê·ª£i ~5-7 ph√∫t ƒë·ªÉ model train xong (ƒë·ªô ch√≠nh x√°c >95%)
        4. Quay l·∫°i trang n√†y ƒë·ªÉ s·ª≠ d·ª•ng!
        
        **L∆∞u √Ω:** Model ch·ªâ c·∫ßn train 1 l·∫ßn duy nh·∫•t, sau ƒë√≥ s·∫Ω ƒë∆∞·ª£c l∆∞u l·∫°i.
        """)
        return
    
    st.info("**8 lo·∫°i h√¨nh:** Tr√≤n, Ch·ªØ nh·∫≠t, Vu√¥ng, Tam gi√°c, Ng≈© gi√°c, L·ª•c gi√°c, Oval, H√¨nh thoi")
    
    tab1, tab2, tab3 = st.tabs(["‚úèÔ∏è V·∫Ω H√¨nh", "üì§ Upload ·∫¢nh", "üé® Demo ·∫¢nh M·∫´u"])
    
    with tab1:
        st.subheader("V·∫Ω h√¨nh h·ªçc")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            canvas_result = st_canvas(
                fill_color="rgba(255, 255, 255, 1)",
                stroke_width=3,
                stroke_color="#FFFFFF",
                background_color="#000000",
                height=320,
                width=320,
                drawing_mode="freedraw",
                key="shape_canvas",
            )
        
        with col2:
            if st.button("üîç Nh·∫≠n D·∫°ng H√¨nh", key="predict_shape_canvas", type="primary"):
                if canvas_result.image_data is not None:
                    input_image = canvas_result.image_data[:, :, 0]
                    
                    if np.sum(input_image) > 0:
                        preprocessed = ImageProcessor.preprocess_for_shapes(input_image, (64, 64))
                        
                        pred_class, shape_name, confidence, probs = model.predict(preprocessed)
                        
                        st.markdown('<div class="prediction-box">', unsafe_allow_html=True)
                        st.markdown(f"### K·∫øt Qu·∫£: **{shape_name}**")
                        st.markdown(f"**ƒê·ªô tin c·∫≠y:** {confidence*100:.2f}%")
                        st.progress(float(confidence))
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                        st.markdown("#### Ph√¢n B·ªë X√°c Su·∫•t")
                        prob_df = pd.DataFrame({
                            'H√¨nh': [ShapeGenerator.SHAPE_CLASSES[i] for i in range(len(probs))],
                            'X√°c su·∫•t (%)': probs * 100
                        })
                        st.bar_chart(prob_df.set_index('H√¨nh'))
                    else:
                        st.warning("Vui l√≤ng v·∫Ω m·ªôt h√¨nh!")
    
    with tab2:
        st.subheader("Upload ·∫£nh ch·ª©a h√¨nh h·ªçc")
        
        uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh", type=['png', 'jpg', 'jpeg'], key="shape_upload")
        
        if uploaded_file is not None:
            image = Image.open(uploaded_file)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.image(image, caption="·∫¢nh g·ªëc", use_container_width=True)
            
            preprocessed = ImageProcessor.preprocess_for_shapes(image, (64, 64))
            pred_class, shape_name, confidence, probs = model.predict(preprocessed)
            
            with col2:
                st.markdown('<div class="prediction-box">', unsafe_allow_html=True)
                st.markdown(f"### K·∫øt Qu·∫£: **{shape_name}**")
                st.markdown(f"**ƒê·ªô tin c·∫≠y:** {confidence*100:.2f}%")
                st.progress(float(confidence))
                st.markdown('</div>', unsafe_allow_html=True)
                
                st.markdown("#### Top 3 D·ª± ƒêo√°n")
                top3_indices = np.argsort(probs)[-3:][::-1]
                for idx in top3_indices:
                    st.write(f"{ShapeGenerator.SHAPE_CLASSES[idx]}: {probs[idx]*100:.2f}%")
    
    with tab3:
        st.subheader("Demo v·ªõi ·∫£nh m·∫´u")
        
        import os
        sample_dir = 'sample_images/shapes'
        
        if os.path.exists(sample_dir):
            sample_files = [f for f in os.listdir(sample_dir) if f.endswith('.png')]
            
            if sample_files:
                selected_sample = st.selectbox("Ch·ªçn ·∫£nh m·∫´u", sample_files)
                
                if selected_sample:
                    image_path = os.path.join(sample_dir, selected_sample)
                    image = Image.open(image_path)
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.image(image, caption=selected_sample, use_container_width=True)
                    
                    preprocessed = ImageProcessor.preprocess_for_shapes(image, (64, 64))
                    pred_class, shape_name, confidence, probs = model.predict(preprocessed)
                    
                    with col2:
                        st.markdown('<div class="prediction-box">', unsafe_allow_html=True)
                        st.markdown(f"### K·∫øt Qu·∫£: **{shape_name}**")
                        st.markdown(f"**ƒê·ªô tin c·∫≠y:** {confidence*100:.2f}%")
                        st.progress(float(confidence))
                        st.markdown('</div>', unsafe_allow_html=True)
            else:
                st.warning("Ch∆∞a c√≥ ·∫£nh m·∫´u. T·∫°o ·∫£nh m·∫´u ·ªü trang 'Train Model'")
        else:
            st.warning("Ch∆∞a c√≥ th∆∞ m·ª•c ·∫£nh m·∫´u. T·∫°o ·∫£nh m·∫´u ·ªü trang 'Train Model'")

def show_multi_object_page():
    st.header("üéØ Ph√°t Hi·ªán Nhi·ªÅu ƒê·ªëi T∆∞·ª£ng")
    
    shape_model = load_shape_model()
    if shape_model is None:
        st.error("‚ö†Ô∏è **Model Shape ch∆∞a ƒë∆∞·ª£c train!**")
        st.info("""
        **T√≠nh nƒÉng n√†y c·∫ßn Shape Model ƒë·ªÉ ho·∫°t ƒë·ªông.**
        
        Vui l√≤ng v√†o trang **'‚öôÔ∏è Train Model'** ƒë·ªÉ train Shape Model tr∆∞·ªõc (~5-7 ph√∫t).
        """)
        return
    
    st.info("Ph√°t hi·ªán v√† nh·∫≠n d·∫°ng nhi·ªÅu h√¨nh h·ªçc trong c√πng m·ªôt ·∫£nh")
    
    uploaded_file = st.file_uploader("Upload ·∫£nh ch·ª©a nhi·ªÅu h√¨nh", type=['png', 'jpg', 'jpeg'], key="multi_object")
    
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        image_np = np.array(image)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("·∫¢nh g·ªëc")
            st.image(image, use_container_width=True)
        
        with st.spinner("ƒêang ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng..."):
            def preprocess_for_detector(roi):
                return ImageProcessor.preprocess_for_shapes(roi, (64, 64))
            
            detector = MultiObjectDetector(shape_model, preprocess_for_detector, min_area=100)
            detections = detector.detect_objects(image_np)
            
            result_image = detector.draw_detections(image_np, detections)
        
        with col2:
            st.subheader(f"K·∫øt qu·∫£ ({len(detections)} ƒë·ªëi t∆∞·ª£ng)")
            st.image(result_image, use_container_width=True)
        
        st.markdown("---")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üìä Th·ªëng k√™")
            summary = detector.get_detection_summary(detections)
            st.metric("T·ªïng s·ªë ƒë·ªëi t∆∞·ª£ng", summary['total_objects'])
            
            st.markdown("**Ph√¢n lo·∫°i:**")
            for shape_name, count in summary['objects_by_class'].items():
                st.write(f"- {shape_name}: {count}")
        
        with col2:
            st.subheader("üìã Chi ti·∫øt")
            if detections:
                details = []
                for i, det in enumerate(detections):
                    details.append({
                        'STT': i + 1,
                        'Lo·∫°i h√¨nh': det['name'],
                        'ƒê·ªô tin c·∫≠y (%)': f"{det['confidence']*100:.2f}",
                        'V·ªã tr√≠ (x,y,w,h)': f"({det['bbox'][0]},{det['bbox'][1]},{det['bbox'][2]},{det['bbox'][3]})"
                    })
                
                details_df = pd.DataFrame(details)
                st.dataframe(details_df, use_container_width=True)
                
                csv = details_df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="üì• T·∫£i k·∫øt qu·∫£ (CSV)",
                    data=csv,
                    file_name='detection_results.csv',
                    mime='text/csv',
                )

def show_image_processing_page():
    st.header("üñºÔ∏è X·ª≠ L√Ω ·∫¢nh N√¢ng Cao")
    
    st.markdown("""
    Trang n√†y demo c√°c k·ªπ thu·∫≠t x·ª≠ l√Ω ·∫£nh ƒë∆∞·ª£c s·ª≠ d·ª•ng trong preprocessing:
    - **Filters:** L√†m m·ªãn, kh·ª≠ nhi·ªÖu
    - **Edge Detection:** Ph√°t hi·ªán bi√™n c·∫°nh
    - **Segmentation:** Ph√¢n ƒëo·∫°n ·∫£nh
    """)
    
    uploaded_file = st.file_uploader("Upload ·∫£nh ƒë·ªÉ x·ª≠ l√Ω", type=['png', 'jpg', 'jpeg'], key="image_processing")
    
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        image_np = np.array(image)
        
        st.subheader("·∫¢nh g·ªëc")
        st.image(image, use_container_width=True)
        
        st.markdown("---")
        
        tab1, tab2, tab3 = st.tabs(["üîß Filters", "üìê Edge Detection", "üé® Segmentation"])
        
        with tab1:
            st.subheader("B·ªô l·ªçc ·∫£nh")
            
            filter_type = st.selectbox(
                "Ch·ªçn b·ªô l·ªçc",
                ["Gaussian Blur", "Median Filter", "Bilateral Filter", "Sharpen"]
            )
            
            gray = ImageProcessor.convert_to_grayscale(image_np)
            
            if filter_type == "Gaussian Blur":
                kernel_size = st.slider("Kernel size", 3, 15, 5, step=2)
                processed = ImageProcessor.apply_gaussian_blur(gray, kernel_size)
            elif filter_type == "Median Filter":
                kernel_size = st.slider("Kernel size", 3, 15, 5, step=2)
                processed = ImageProcessor.apply_median_filter(gray, kernel_size)
            elif filter_type == "Bilateral Filter":
                processed = ImageProcessor.apply_bilateral_filter(gray)
            else:
                processed = ImageProcessor.sharpen_image(gray)
            
            col1, col2 = st.columns(2)
            with col1:
                st.image(gray, caption="·∫¢nh g·ªëc (Grayscale)", use_container_width=True)
            with col2:
                st.image(processed, caption=f"Sau {filter_type}", use_container_width=True)
        
        with tab2:
            st.subheader("Ph√°t hi·ªán bi√™n")
            
            edge_type = st.selectbox(
                "Ch·ªçn ph∆∞∆°ng ph√°p",
                ["Canny", "Sobel"]
            )
            
            gray = ImageProcessor.convert_to_grayscale(image_np)
            
            if edge_type == "Canny":
                col1, col2 = st.columns(2)
                with col1:
                    threshold1 = st.slider("Threshold 1", 0, 255, 100)
                with col2:
                    threshold2 = st.slider("Threshold 2", 0, 255, 200)
                edges = ImageProcessor.detect_edges_canny(gray, threshold1, threshold2)
            else:
                edges = ImageProcessor.detect_edges_sobel(gray)
            
            col1, col2 = st.columns(2)
            with col1:
                st.image(gray, caption="·∫¢nh g·ªëc", use_container_width=True)
            with col2:
                st.image(edges, caption=f"Edges ({edge_type})", use_container_width=True)
        
        with tab3:
            st.subheader("Ph√¢n ƒëo·∫°n ·∫£nh")
            
            seg_type = st.selectbox(
                "Ch·ªçn ph∆∞∆°ng ph√°p",
                ["Binary Threshold", "Otsu Threshold", "Adaptive Threshold", "Watershed"]
            )
            
            gray = ImageProcessor.convert_to_grayscale(image_np)
            
            if seg_type == "Binary Threshold":
                threshold_val = st.slider("Threshold", 0, 255, 127)
                segmented = ImageProcessor.threshold_binary(gray, threshold_val)
            elif seg_type == "Otsu Threshold":
                segmented = ImageProcessor.threshold_otsu(gray)
            elif seg_type == "Adaptive Threshold":
                block_size = st.slider("Block size", 3, 21, 11, step=2)
                segmented = ImageProcessor.adaptive_threshold(gray, block_size)
            else:
                segmented = ImageProcessor.watershed_segmentation(image_np)
            
            col1, col2 = st.columns(2)
            with col1:
                st.image(gray, caption="·∫¢nh g·ªëc", use_container_width=True)
            with col2:
                st.image(segmented, caption=f"Segmented ({seg_type})", use_container_width=True)

def show_feature_maps_page():
    st.header("üìä Tr√≠ch Xu·∫•t ƒê·∫∑c Tr∆∞ng (Feature Maps)")
    
    st.info("Visualize c√°ch CNN h·ªçc v√† tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng t·ª´ ·∫£nh")
    
    model_type = st.radio("Ch·ªçn model", ["MNIST", "Shape"])
    
    if model_type == "MNIST":
        model = load_mnist_model()
        preprocess_func = ImageProcessor.preprocess_for_mnist
    else:
        model = load_shape_model()
        preprocess_func = lambda img: ImageProcessor.preprocess_for_shapes(img, (64, 64))
    
    if model is None:
        st.error("Model ch∆∞a s·∫µn s√†ng.")
        st.error(f"‚ö†Ô∏è **Model {model_type} ch∆∞a ƒë∆∞·ª£c train!**")
        st.info("""
        **ƒê·ªÉ s·ª≠ d·ª•ng t√≠nh nƒÉng n√†y:**
        Vui l√≤ng v√†o trang **'‚öôÔ∏è Train Model'** ƒë·ªÉ train model tr∆∞·ªõc.
        """)
        return
    
    uploaded_file = st.file_uploader("Upload ·∫£nh", type=['png', 'jpg', 'jpeg'], key="feature_maps")
    
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("·∫¢nh ƒë·∫ßu v√†o")
            st.image(image, use_container_width=True)
        
        preprocessed = preprocess_func(image)
        
        with col2:
            st.subheader("·∫¢nh sau preprocessing")
            st.image(preprocessed.squeeze(), use_container_width=True, clamp=True)
        
        st.markdown("---")
        
        visualizer = FeatureVisualizer(model.model)
        conv_layers = visualizer.get_conv_layers()
        
        if conv_layers:
            selected_layer = st.selectbox("Ch·ªçn layer ƒë·ªÉ visualize", conv_layers)
            
            layer_index = conv_layers.index(selected_layer)
            
            max_filters = st.slider("S·ªë l∆∞·ª£ng filters hi·ªÉn th·ªã", 4, 32, 16, step=4)
            
            with st.spinner("ƒêang t·∫°o feature maps..."):
                fig = visualizer.visualize_feature_maps(preprocessed, layer_index, max_filters)
                st.pyplot(fig)
            
            if st.checkbox("Hi·ªÉn th·ªã t·∫•t c·∫£ layers"):
                with st.spinner("ƒêang t·∫°o visualization cho t·∫•t c·∫£ layers..."):
                    figures = visualizer.visualize_all_layers(preprocessed, max_filters_per_layer=8)
                    
                    for fig in figures:
                        st.pyplot(fig)
        else:
            st.warning("Kh√¥ng t√¨m th·∫•y convolutional layers trong model")

def show_training_page():
    st.header("‚öôÔ∏è Train Model")
    
    st.warning("‚è∞ Training c√≥ th·ªÉ m·∫•t v√†i ph√∫t. Vui l√≤ng ƒë·ª£i cho ƒë·∫øn khi ho√†n t·∫•t.")
    
    tab1, tab2, tab3 = st.tabs(["üî¢ Train MNIST", "üî∑ Train Shape Model", "üé® T·∫°o ·∫¢nh M·∫´u"])
    
    with tab1:
        st.subheader("Train MNIST Model")
        
        mnist_trained, _ = check_models_trained()
        if mnist_trained:
            st.success("‚úÖ Model MNIST ƒë√£ ƒë∆∞·ª£c train! B·∫°n c√≥ th·ªÉ train l·∫°i ƒë·ªÉ c·∫£i thi·ªán ho·∫∑c th·ª≠ tham s·ªë kh√°c.")
        else:
            st.info("‚ö†Ô∏è Model ch∆∞a ƒë∆∞·ª£c train. H√£y train ngay ƒë·ªÉ s·ª≠ d·ª•ng t√≠nh nƒÉng nh·∫≠n d·∫°ng ch·ªØ s·ªë!")
        
        st.markdown("""
        **Dataset:** MNIST (70,000 ·∫£nh ch·ªØ s·ªë vi·∫øt tay)
        - Training: 60,000 ·∫£nh
        - Test: 10,000 ·∫£nh
        - Classes: 0-9 (10 classes)
        - **Th·ªùi gian:** ~2-3 ph√∫t
        - **ƒê·ªô ch√≠nh x√°c mong ƒë·ª£i:** >95%
        """)
        
        col1, col2 = st.columns(2)
        with col1:
            epochs_mnist = st.number_input("S·ªë epochs", 1, 50, 10, key="mnist_epochs")
        with col2:
            batch_size_mnist = st.number_input("Batch size", 32, 256, 128, key="mnist_batch")
        
        if st.button("üöÄ B·∫Øt ƒë·∫ßu Training MNIST", type="primary"):
            with st.spinner("ƒêang training model..."):
                model = MNISTModel()
                
                progress_text = st.empty()
                progress_text.text("ƒêang load dataset...")
                
                history = model.train(epochs=epochs_mnist, batch_size=batch_size_mnist)
                
                progress_text.text("Training ho√†n t·∫•t!")
                
                st.success("‚úÖ Training MNIST model th√†nh c√¥ng!")
                
                visualizer = FeatureVisualizer(model.model)
                fig = visualizer.plot_training_history(history)
                st.pyplot(fig)
                
                final_acc = history.history['val_accuracy'][-1]
                st.metric("Validation Accuracy", f"{final_acc*100:.2f}%")
    
    with tab2:
        st.subheader("Train Shape Recognition Model")
        
        _, shape_trained = check_models_trained()
        if shape_trained:
            st.success("‚úÖ Model Shape ƒë√£ ƒë∆∞·ª£c train! B·∫°n c√≥ th·ªÉ train l·∫°i ƒë·ªÉ c·∫£i thi·ªán ho·∫∑c th·ª≠ tham s·ªë kh√°c.")
        else:
            st.info("‚ö†Ô∏è Model ch∆∞a ƒë∆∞·ª£c train. H√£y train ngay ƒë·ªÉ s·ª≠ d·ª•ng t√≠nh nƒÉng nh·∫≠n d·∫°ng h√¨nh h·ªçc!")
        
        st.markdown("""
        **Dataset:** Synthetic Shapes (t·ª± t·∫°o)
        - Shapes: Circle, Rectangle, Square, Triangle, Pentagon, Hexagon, Oval, Diamond
        - Augmentation: Rotation, Noise
        - **Th·ªùi gian:** ~5-7 ph√∫t
        - **ƒê·ªô ch√≠nh x√°c mong ƒë·ª£i:** >95%
        """)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            epochs_shape = st.number_input("S·ªë epochs", 1, 50, 30, key="shape_epochs")
        with col2:
            batch_size_shape = st.number_input("Batch size", 32, 128, 64, key="shape_batch")
        with col3:
            samples_per_class = st.number_input("Samples/class", 500, 2000, 1000, key="samples")
        
        if st.button("üöÄ B·∫Øt ƒë·∫ßu Training Shape Model", type="primary"):
            with st.spinner("ƒêang training model..."):
                model = ShapeModel(input_size=64)
                
                progress_text = st.empty()
                progress_text.text("ƒêang t·∫°o dataset...")
                
                history = model.train(
                    epochs=epochs_shape,
                    batch_size=batch_size_shape,
                    samples_per_class=samples_per_class
                )
                
                progress_text.text("Training ho√†n t·∫•t!")
                
                st.success("‚úÖ Training Shape model th√†nh c√¥ng!")
                
                visualizer = FeatureVisualizer(model.model)
                fig = visualizer.plot_training_history(history)
                st.pyplot(fig)
                
                final_acc = history.history['val_accuracy'][-1]
                st.metric("Validation Accuracy", f"{final_acc*100:.2f}%")
    
    with tab3:
        st.subheader("T·∫°o ·∫¢nh M·∫´u")
        
        st.markdown("T·∫°o ·∫£nh m·∫´u cho demo v√† testing")
        
        num_samples = st.number_input("S·ªë ·∫£nh m·∫´u m·ªói lo·∫°i h√¨nh", 1, 10, 5)
        
        if st.button("üé® T·∫°o ·∫¢nh M·∫´u", type="primary"):
            with st.spinner("ƒêang t·∫°o ·∫£nh m·∫´u..."):
                ShapeGenerator.save_sample_images(samples=num_samples)
                st.success(f"‚úÖ ƒê√£ t·∫°o {num_samples * 8} ·∫£nh m·∫´u t·∫°i sample_images/shapes/")
                
                import os
                sample_dir = 'sample_images/shapes'
                sample_files = [f for f in os.listdir(sample_dir) if f.endswith('.png')][:8]
                
                cols = st.columns(4)
                for i, file in enumerate(sample_files):
                    with cols[i % 4]:
                        img = Image.open(os.path.join(sample_dir, file))
                        st.image(img, caption=file, use_container_width=True)

def show_guide_page():
    st.header("üìö H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng")
    
    st.markdown("""
    ## üéØ Quy Tr√¨nh S·ª≠ D·ª•ng
    
    ### B∆∞·ªõc 1: Train Models
    1. V√†o trang **"‚öôÔ∏è Train Model"**
    2. Train MNIST model (10 epochs, ~2-3 ph√∫t)
    3. Train Shape model (30 epochs, ~5-7 ph√∫t)
    4. T·∫°o ·∫£nh m·∫´u cho demo
    
    ### B∆∞·ªõc 2: S·ª≠ D·ª•ng T√≠nh NƒÉng
    
    #### üî¢ Nh·∫≠n D·∫°ng Ch·ªØ S·ªë (MNIST)
    - **V·∫Ω tay:** V·∫Ω s·ªë t·ª´ 0-9 tr√™n canvas
    - **Upload:** Upload ·∫£nh ch·ª©a ch·ªØ s·ªë
    - **Batch:** X·ª≠ l√Ω nhi·ªÅu ·∫£nh c√πng l√∫c
    
    #### üî∑ Nh·∫≠n D·∫°ng H√¨nh H·ªçc
    - Nh·∫≠n d·∫°ng 8 lo·∫°i h√¨nh: Tr√≤n, Vu√¥ng, Ch·ªØ nh·∫≠t, Tam gi√°c, Ng≈© gi√°c, L·ª•c gi√°c, Oval, H√¨nh thoi
    - V·∫Ω ho·∫∑c upload ·∫£nh
    - Xem demo v·ªõi ·∫£nh m·∫´u
    
    #### üéØ Ph√°t Hi·ªán Nhi·ªÅu ƒê·ªëi T∆∞·ª£ng
    - Upload ·∫£nh ch·ª©a nhi·ªÅu h√¨nh
    - T·ª± ƒë·ªông ph√°t hi·ªán v√† v·∫Ω bounding boxes
    - Export k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng CSV
    
    #### üñºÔ∏è X·ª≠ L√Ω ·∫¢nh N√¢ng Cao
    - **Filters:** Gaussian, Median, Bilateral, Sharpen
    - **Edge Detection:** Canny, Sobel
    - **Segmentation:** Binary, Otsu, Adaptive, Watershed
    
    #### üìä Feature Maps
    - Visualize c√°ch CNN h·ªçc ƒë·∫∑c tr∆∞ng
    - Xem feature maps t·ª´ c√°c convolutional layers
    - Hi·ªÉu qu√° tr√¨nh tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng
    
    ---
    
    ## üî¨ Ki·∫øn Tr√∫c CNN
    
    ### MNIST Model
    ```
    Input (28x28x1)
    ‚Üì
    Conv2D(32) + ReLU ‚Üí MaxPool ‚Üí BatchNorm
    ‚Üì
    Conv2D(64) + ReLU ‚Üí MaxPool ‚Üí BatchNorm
    ‚Üì
    Conv2D(128) + ReLU ‚Üí BatchNorm
    ‚Üì
    Flatten ‚Üí Dense(128) ‚Üí Dropout ‚Üí Dense(10) + Softmax
    ```
    
    ### Shape Model
    ```
    Input (64x64x1)
    ‚Üì
    2x Conv2D(32) + ReLU ‚Üí MaxPool ‚Üí BatchNorm ‚Üí Dropout
    ‚Üì
    2x Conv2D(64) + ReLU ‚Üí MaxPool ‚Üí BatchNorm ‚Üí Dropout
    ‚Üì
    2x Conv2D(128) + ReLU ‚Üí MaxPool ‚Üí BatchNorm ‚Üí Dropout
    ‚Üì
    Flatten ‚Üí Dense(256) ‚Üí Dropout ‚Üí Dense(8) + Softmax
    ```
    
    ---
    
    ## üìä X·ª≠ L√Ω ·∫¢nh Pipeline
    
    1. **Input:** ·∫¢nh g·ªëc (RGB/Grayscale)
    2. **Grayscale:** Chuy·ªÉn sang ·∫£nh x√°m
    3. **Resize:** Resize v·ªÅ k√≠ch th∆∞·ªõc chu·∫©n (28x28 ho·∫∑c 64x64)
    4. **Normalize:** Chu·∫©n h√≥a pixel values v·ªÅ [0, 1]
    5. **Reshape:** Th√™m channel dimension
    6. **Predict:** ƒê∆∞a v√†o CNN model
    
    ---
    
    ## üí° Tips & Tricks
    
    ### MNIST
    - V·∫Ω s·ªë to, r√µ r√†ng
    - Tr√°nh v·∫Ω qu√° nhi·ªÅu n√©t
    - S·ªë n√™n n·∫±m ·ªü gi·ªØa canvas
    
    ### Shape Detection
    - V·∫Ω h√¨nh ƒë∆°n gi·∫£n, r√µ r√†ng
    - Tr√°nh v·∫Ω c√°c h√¨nh ch·ªìng l√™n nhau
    - H√¨nh n√™n c√≥ k√≠ch th∆∞·ªõc v·ª´a ph·∫£i
    
    ### Multi-Object Detection
    - Upload ·∫£nh c√≥ background ƒë∆°n gi·∫£n
    - C√°c h√¨nh n√™n c√°ch nhau r√µ r√†ng
    - Tr√°nh c√°c h√¨nh qu√° nh·ªè
    
    ---
    
    ## üõ†Ô∏è C·∫•u Tr√∫c Code
    
    ```
    ‚îú‚îÄ‚îÄ app.py                      # Main Streamlit app
    ‚îú‚îÄ‚îÄ image_processor.py          # X·ª≠ l√Ω ·∫£nh (filters, edges, segmentation)
    ‚îú‚îÄ‚îÄ mnist_model.py              # MNIST CNN model
    ‚îú‚îÄ‚îÄ shape_model.py              # Shape recognition CNN model
    ‚îú‚îÄ‚îÄ shape_generator.py          # T·∫°o synthetic shape dataset
    ‚îú‚îÄ‚îÄ multi_object_detector.py    # Ph√°t hi·ªán nhi·ªÅu ƒë·ªëi t∆∞·ª£ng
    ‚îú‚îÄ‚îÄ feature_visualizer.py       # Visualize feature maps
    ‚îú‚îÄ‚îÄ models/                     # Saved models
    ‚îî‚îÄ‚îÄ sample_images/              # ·∫¢nh m·∫´u demo
    ```
    
    ---
    
    ## üìñ T√†i Li·ªáu Tham Kh·∫£o
    
    - **TensorFlow/Keras:** https://www.tensorflow.org/
    - **OpenCV:** https://opencv.org/
    - **Streamlit:** https://streamlit.io/
    - **MNIST Dataset:** http://yann.lecun.com/exdb/mnist/
    
    ---
    
    ## üë®‚Äçüíª Ph√°t Tri·ªÉn Th√™m
    
    C√≥ th·ªÉ m·ªü r·ªông d·ª± √°n v·ªõi:
    - ‚ú® Nh·∫≠n d·∫°ng ch·ªØ c√°i (A-Z)
    - ‚ú® Nh·∫≠n d·∫°ng ch·ªØ vi·∫øt ti·∫øng Vi·ªát
    - ‚ú® Object detection v·ªõi YOLO/SSD
    - ‚ú® Data augmentation n√¢ng cao
    - ‚ú® Transfer learning v·ªõi pre-trained models
    - ‚ú® Real-time detection qua webcam
    """)

if __name__ == "__main__":
    main()
